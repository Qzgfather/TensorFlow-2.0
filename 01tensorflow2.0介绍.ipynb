{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow介绍\n",
    "   TensorFlow 2.0 网站将该项目描述为“端到端开源机器学习平台”。实际上 TensorFlow 已进化成为一个更全面的“工具、库和社区资源生态系统”，可帮助研究人员构建和部署人工智能助力的应用。\n",
    "TensorFlow 2.0 有四大组成部分：\n",
    "- TensorFlow 核心，一个用于开发和训练机器学习模型的开源库；\n",
    "- TensorFlow.js，一个用于在浏览器和 Node.js 上训练和部署模型的 JavaScript 库；\n",
    "- TensorFlow Lite，一个轻量级库，用于在移动和嵌入式设备上部署模型；\n",
    "- TensorFlow Extended，一个在大型生产环境中准备数据、训练、验证和部署模型的平台。\n",
    "\n",
    "TensorFlow 2.0 生态系统包括对 Python、JavaScript 和 Swift 的支持，以及对云、浏览器和边缘设备的部署支持。TensorBoard（可视化）和 TensorFlow Hub（模型库）都是很有用的工具。TensorFlow Extended（TFX）则支持端到端生产流水线。[参考](http://baijiahao.baidu.com/sid=1640756159447567798&wfr=spider&for=pc)\n",
    "# 为什么会有这个？\n",
    "   Tensorflow2.0现在已经发布，相比1.x版本有很多显著的改善，作为深度学习新手。tensorflow2.0更加简单上手，本教程[参考](https://github.com/czy36mengfei/tensorflow2_tutorials_chinese)里面的代码对我来说较难理解我对里面的代码进行复现和进一步的讲解，对新手更加友好，如果自己水平有所提升可以参考原教程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更简洁——Keras\n",
    "   keras原本是独立于Tensorflow的高级API可以实现跨平台的模型部署，其后端可以是tensorflow。谷歌将Keras收购后，作为其官方的API并入到Tensorflow2.0中，tf.keras与keras并不完全相同（import keras ≠ from tensorflow import keras）独立的keras在以后将逐渐淡出人们的视野。\n",
    "   \n",
    "## tf.keras 可以运行任何与 Keras 兼容的代码，但请注意：\n",
    "最新版 TensorFlow 中的 tf.keras 版本可能与 PyPI 中的最新 keras 版本不同。请查看 tf.keras.version。\n",
    "保存模型的权重时，tf.keras 默认采用检查点格式。请传递 save_format='h5' 以使用 HDF5。[官方介绍](https://tensorflow.google.cn/guide/keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更方便\n",
    "   如果接触过pytorch，相比pytorch，发现tensorflow 1.x版本过于复杂，比如计算图的定义，会话的定义。在tensorflow 2.0版本中更加方便的应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "variable1 = tf.constant(3)\n",
    "variable2 = tf.constant(2)\n",
    "\n",
    "result = tf.add(variable1, variable2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1一般网络的配置\n",
    "   tensorflow 2.0使用keras可以堆叠式的建立模型。一般分为四个步骤：\n",
    "- 1.网络的定义\n",
    "- 2.模型的编译\n",
    "- 3.喂入数据\n",
    "- 4.定义其他操作（模型的保存，模型参数的可视化）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.1生成数据\n",
    " 在建立模型之前，一般会对所要训练的数据进行整理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2设置训练流程\n",
    "在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。最常见的模型类型是层的堆叠：tf.keras.Sequential 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 988us/sample - loss: 12.3978 - categorical_accuracy: 0.1110 - val_loss: 12.7143 - val_categorical_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 13.1638 - categorical_accuracy: 0.1120 - val_loss: 13.9713 - val_categorical_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 14.8748 - categorical_accuracy: 0.1070 - val_loss: 16.4407 - val_categorical_accuracy: 0.1100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 18.1452 - categorical_accuracy: 0.1130 - val_loss: 20.9342 - val_categorical_accuracy: 0.0950\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 23.2897 - categorical_accuracy: 0.1150 - val_loss: 26.6265 - val_categorical_accuracy: 0.0900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 28.8893 - categorical_accuracy: 0.1050 - val_loss: 32.5985 - val_categorical_accuracy: 0.1150\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 34.9628 - categorical_accuracy: 0.1010 - val_loss: 38.9556 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 37.6530 - categorical_accuracy: 0.100 - 0s 67us/sample - loss: 41.3707 - categorical_accuracy: 0.0970 - val_loss: 46.3646 - val_categorical_accuracy: 0.1150\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 49.9655 - categorical_accuracy: 0.1010 - val_loss: 57.5191 - val_categorical_accuracy: 0.1050\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 62.8709 - categorical_accuracy: 0.0960 - val_loss: 73.0761 - val_categorical_accuracy: 0.0950\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            multiple                  2336      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            multiple                  330       \n",
      "=================================================================\n",
      "Total params: 3,722\n",
      "Trainable params: 3,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1 定义网络\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 2.模型编译——使用compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "\n",
    "# # 3.喂入数据\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))\n",
    "\n",
    "# 4.其他操作——可视化模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3API介绍\n",
    "### tf.keras.Sequential():初始化模型，可以传入参数，也可以不传入，传入的参数是一个包含layer的列表。\n",
    "### tf.keras.layers.Dense():定义全连接层，运算逻辑：Y = W·X+b，  \n",
    "- **activation**：要使用的激活函数。如果您未指定任何内容，则不会应用任何激活（即“线性”激活：）a(x) = x，\n",
    "- **use_bias**：布尔值，层是否使用偏差矢量。即是否在进行W·X后加上偏置b。\n",
    "- **kernel_initializer**：权重矩阵的初始化程序。\n",
    "- **bias_initializer**：偏置向量的初始化程序。\n",
    "- **kernel_regularizer**：正则化函数应用于kernel权重矩阵，L1或者L2正则化。。\n",
    "- **bias_regularizer**：正则化函数应用于偏差向量，L1或者L2正则化。\n",
    "\n",
    "### tf.keras.Model.compile() ：编译模型，tf.keras.Model一般是你定义的模型名字。\n",
    "- **optimizer**：此对象会指定训练过程。从 tf.keras.optimizers 模块向其传递优化器实例，例如 tf.keras.optimizers.Adam、tf.keras.optimizers.SGD,\n",
    "- **loss**：要在优化期间最小化的函数。常见选择包括均方误差 (mean_squared_error：mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。比如：tf.keras.losses.categorical_crossentropy（交叉熵准确率）。\n",
    "- **metrics**：用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。\n",
    "- **optimizer列举：**\n",
    "\n",
    "算法|字符表示|对象表示\n",
    ":-|:-:|:-:\n",
    "Adam|'adam'|tf.keras.optimizers.Adam\n",
    "SGD|'SGD'|tf.keras.optimizers.SGD\n",
    "\n",
    "- **loss列举:**\n",
    "\n",
    "算法|字符表示|对象表示\n",
    ":-|:-:|:-:\n",
    "交叉熵 |'categorical_crossentropy'|tf.keras.losses.categorical_crossentropy\n",
    "二分类交叉熵|'binary_crossentropy'|tf.keras.losses.binary_crossentropy\n",
    "MSE|'mse'|tf.keras.losses.mean_squared_error,tf.keras.losses.mse,tf.keras.metrics.MSE\n",
    "mae|'mae'|tf.losses.MAE,tf.losses.mae,tf.losses.mean_absolute_error\n",
    "\n",
    "### tf.keras.Model.fit()：喂入数据。\n",
    "- **epochs**：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。\n",
    "- **batch_size**：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。\n",
    "- **validation_data**：在对模型进行原型设计时，可以轻松监控该模型在某些验证数据上达到的效果。输入此参数（输入和标签元组）可以让该模型在每个周期结束时显示所传递数据的损失和指标。\n",
    "\n",
    "### 其他喂入数据的方法：tf.data.Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((None, 72), (None, 10)), types: (tf.float64, tf.float64)>\n",
      "WARNING:tensorflow:Layer sequential_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 11.9120 - categorical_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 12.2187 - categorical_accuracy: 0.1040\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 13.3768 - categorical_accuracy: 0.1030\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 15.4902 - categorical_accuracy: 0.1030\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 18.1487 - categorical_accuracy: 0.1030\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 20.2402 - categorical_accuracy: 0.1030\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 22.2389 - categorical_accuracy: 0.1080\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 26.5437 - categorical_accuracy: 0.1090\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 32.6566 - categorical_accuracy: 0.1160\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 39.2358 - categorical_accuracy: 0.1090\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            multiple                  2336      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            multiple                  330       \n",
      "=================================================================\n",
      "Total params: 3,722\n",
      "Trainable params: 3,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1 定义网络\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 2.模型编译——使用compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "\n",
    "# # 3.喂入数据_2\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)) # 生成一个数据\n",
    "dataset = dataset.batch(100)\n",
    "dataset = dataset.repeat()\n",
    "print(dataset)\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=10)\n",
    "\n",
    "\n",
    "\n",
    "# # 4.其他操作——可视化模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：一般在进行批次训练时经常有三个参数容易弄混：\n",
    "- 批大小：batch_size,默认32\n",
    "- 训练轮数：epochs，\n",
    "- 批个数：steps_per_epoch，steps_per_epoch=总样本数（all_samples) / 批大小(batch_size）\n",
    "\n",
    "现在用的优化器SGD是stochastic gradient descent的缩写，但不代表是一个样本就更新一回，还是基于mini-batch的。\n",
    "那 batch epoch iteration代表什么呢？\n",
    "- （1）batchsize：批大小。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练；\n",
    "- （2）iteration：1个iteration等于使用batchsize个样本训练一次；\n",
    "- （3）epoch：1个epoch等于使用训练集中的全部样本训练一次，通俗的讲epoch的值就是整个数据集被轮几次。\n",
    "\n",
    "比如训练集有500个样本，batchsize = 10 ，那么训练完整个样本集：iteration=50，epoch=1.\n",
    "\n",
    "作者：bboysky45 \n",
    "来源：CSDN \n",
    "原文：https://blog.csdn.net/qq_18668137/article/details/80883350 \n",
    "版权声明：本文为博主原创文章，转载请附上博文链接！\n",
    "\n",
    "官方网站上，阐述了 repeat 在 shuffle 之前使用可以有效提高性能，但是模糊了数据样本的 epoch 实际上，可以这样理解shuffle取之前已经重置了源数据集， 即先repeat，后shuffle。tf会将数据集乘以repeat次数，然后整个打乱一次，把它当作一个数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4模型的评估与预测\n",
    "训练好模型后可以对模型进行评估,使用的API时是：model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 9ms/step - loss: 72.8322 - categorical_accuracy: 0.0979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[72.8322021484375, 0.09791667]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型的评估\n",
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8827932e-04 4.6541311e-07 1.7521141e-21 ... 8.7908869e-13\n",
      "  4.3893911e-10 1.7103927e-04]\n",
      " [3.1108255e-04 2.0661598e-07 1.6624059e-21 ... 4.2849480e-13\n",
      "  5.3313892e-10 2.3800629e-04]\n",
      " [1.3693042e-04 2.1717564e-07 2.8686385e-22 ... 2.6706458e-13\n",
      "  3.3628944e-10 1.3130548e-04]\n",
      " ...\n",
      " [5.6340022e-04 2.2013110e-06 5.8089653e-19 ... 3.2290354e-11\n",
      "  7.3468160e-09 3.4577397e-04]\n",
      " [5.0389755e-04 1.0036985e-06 1.3823169e-19 ... 7.2727219e-12\n",
      "  4.2529877e-09 5.0028716e-04]\n",
      " [6.1346550e-04 7.8577131e-07 3.4149053e-19 ... 7.8434672e-12\n",
      "  5.0080353e-09 5.5151404e-04]]\n"
     ]
    }
   ],
   "source": [
    "# 模型的预测\n",
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
