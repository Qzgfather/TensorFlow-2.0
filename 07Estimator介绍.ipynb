{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "本教程将向您展示如何使用 Estimators 解决 Tensorflow 中的鸢尾花（Iris）分类问题。**Estimator 是 Tensorflow 完整模型的高级表示，它被设计用于轻松扩展和异步训练**。更多细节请参阅 Estimators。\n",
    "\n",
    "请注意，在 Tensorflow 2.0 中，Keras API 可以完成许多相同的任务，而且被认为是一个更易学习的API。如果您刚刚开始入门，我们建议您从 Keras 开始。有关 Tensorflow 2.0 中可用高级API的更多信息，请参阅 Keras标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据集\n",
    "本文档中的示例程序构建并测试了一个模型，该模型根据花萼和花瓣的大小将鸢尾花分成三种物种。您将使用鸢尾花数据集训练模型。该数据集包括四个特征和一个标签。这四个特征确定了单个鸢尾花的以下植物学特征：\n",
    "- 花萼长度\n",
    "- 花萼宽度\n",
    "- 花瓣长度\n",
    "- 花瓣宽度\n",
    "\n",
    "根据这些信息，您可以定义一些有用的常量来解析数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 下载解析数据集\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# 去除标签\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# 标签列现已从数据中删除\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Estimator 编程概述\n",
    "现在您已经设定好了数据，您可以使用 Tensorflow Estimator 定义模型。Estimator 是从 tf.estimator.Estimator 中派生的任何类。Tensorflow提供了一组tf.estimator(例如，LinearRegressor)来实现常见的机器学习算法。此外，您可以编写您自己的自定义 Estimator。入门阶段我们建议使用预创建Estimator。\n",
    "\n",
    "为了编写基于预创建的 Estimator 的 Tensorflow 项目，您必须完成以下工作：\n",
    "\n",
    "- 创建一个或多个输入函数\n",
    "- 定义模型的特征列\n",
    "- 实例化一个 Estimator，指定特征列和各种超参数。\n",
    "- 在 Estimator 对象上调用一个或多个方法，传递合适的输入函数以作为数据源。\n",
    "我们来看看这些任务是如何在鸢尾花分类中实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.创建输入函数\n",
    "您必须创建输入函数来提供用于训练、评估和预测的数据。\n",
    "\n",
    "输入函数是一个返回 tf.data.Dataset 对象的函数，此对象会输出下列含两个元素的元组：\n",
    "\n",
    "- features——Python字典，其中：\n",
    " - 每个键都是特征名称\n",
    " - 每个值都是包含此特征所有值的数组\n",
    "- label 包含每个样本的标签的值的数组。\n",
    "为了向您展示输入函数的格式，请查看下面这个简单的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您的输入函数可以以您喜欢的方式生成 features 字典与 label 列表。但是，我们建议使用 Tensorflow 的 Dataset API，该 API 可以用来解析各种类型的数据。\n",
    "\n",
    "Dataset API 可以为您处理很多常见情况。例如，使用 Dataset API，您可以轻松地从大量文件中并行读取记录，并将它们合并为单个数据流。\n",
    "\n",
    "为了简化此示例，我们将使用 pandas 加载数据，并利用此内存数据构建输入管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # 将输入转换为数据集。\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # 如果在训练模式下混淆并重复数据。\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.定义特征列（feature columns）\n",
    "特征列（feature columns）是一个对象，用于描述模型应该如何使用特征字典中的原始输入数据。当您构建一个 Estimator 模型的时候，您会向其传递一个特征列的列表，其中包含您希望模型使用的每个特征。tf.feature_column 模块提供了许多为模型表示数据的选项。\n",
    "\n",
    "对于鸢尾花问题，4 个原始特征是数值，因此我们将构建一个特征列的列表，以告知 Estimator 模型将 4 个特征都表示为 32 位浮点值。故创建特征列的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 特征列描述了如何使用输入。\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "print(my_feature_columns)\n",
    "print(type(my_feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.实例化 Estimator\n",
    "鸢尾花为题是一个经典的分类问题。幸运的是，Tensorflow 提供了几个预创建的 Estimator 分类器，其中包括：\n",
    "\n",
    "- tf.estimator.DNNClassifier 用于多类别分类的深度模型\n",
    "- tf.estimator.DNNLinearCombinedClassifier 用于广度与深度模型\n",
    "- tf.estimator.LinearClassifier 用于基于线性模型的分类器\n",
    "\n",
    "对于鸢尾花问题，tf.estimator.LinearClassifier 似乎是最好的选择。您可以这样实例化该 Estimator："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpzlkzqo2h\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpzlkzqo2h', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002428E6F7908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 构建一个拥有两个隐层，隐藏节点分别为 30 和 10 的深度神经网络。\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # 隐层所含结点数量分别为 30 和 10.\n",
    "    hidden_units=[30, 10],\n",
    "    # 模型必须从三个类别中做出选择。\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.训练、评估和预测\n",
    "\n",
    "我们已经有一个 Estimator 对象，现在可以调用方法来执行下列操作：\n",
    "\n",
    "- 训练模型。\n",
    "- 评估经过训练的模型。\n",
    "- 使用经过训练的模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py:550: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adagrad.py:108: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:337: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.TensorShape([]).\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1486: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpzlkzqo2h\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4872974, step = 0\n",
      "INFO:tensorflow:global_step/sec: 207.502\n",
      "INFO:tensorflow:loss = 0.9925542, step = 100 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.559\n",
      "INFO:tensorflow:loss = 0.8958357, step = 200 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.148\n",
      "INFO:tensorflow:loss = 0.8535943, step = 300 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.178\n",
      "INFO:tensorflow:loss = 0.8091775, step = 400 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.018\n",
      "INFO:tensorflow:loss = 0.78869647, step = 500 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.926\n",
      "INFO:tensorflow:loss = 0.76991516, step = 600 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.393\n",
      "INFO:tensorflow:loss = 0.7521089, step = 700 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.233\n",
      "INFO:tensorflow:loss = 0.7235911, step = 800 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.286\n",
      "INFO:tensorflow:loss = 0.70947915, step = 900 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.724\n",
      "INFO:tensorflow:loss = 0.6865169, step = 1000 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.864\n",
      "INFO:tensorflow:loss = 0.6744465, step = 1100 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.072\n",
      "INFO:tensorflow:loss = 0.662493, step = 1200 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.133\n",
      "INFO:tensorflow:loss = 0.657682, step = 1300 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.854\n",
      "INFO:tensorflow:loss = 0.6306461, step = 1400 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.666\n",
      "INFO:tensorflow:loss = 0.61834276, step = 1500 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.789\n",
      "INFO:tensorflow:loss = 0.58515465, step = 1600 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.061\n",
      "INFO:tensorflow:loss = 0.58604693, step = 1700 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.191\n",
      "INFO:tensorflow:loss = 0.56899214, step = 1800 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.505\n",
      "INFO:tensorflow:loss = 0.55765474, step = 1900 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.636\n",
      "INFO:tensorflow:loss = 0.55224603, step = 2000 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.668\n",
      "INFO:tensorflow:loss = 0.5485797, step = 2100 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.329\n",
      "INFO:tensorflow:loss = 0.5377922, step = 2200 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.862\n",
      "INFO:tensorflow:loss = 0.52691615, step = 2300 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.063\n",
      "INFO:tensorflow:loss = 0.5267806, step = 2400 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.312\n",
      "INFO:tensorflow:loss = 0.5165996, step = 2500 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.663\n",
      "INFO:tensorflow:loss = 0.5085376, step = 2600 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.742\n",
      "INFO:tensorflow:loss = 0.5005513, step = 2700 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.56\n",
      "INFO:tensorflow:loss = 0.4912153, step = 2800 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.89\n",
      "INFO:tensorflow:loss = 0.49245957, step = 2900 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.261\n",
      "INFO:tensorflow:loss = 0.4797266, step = 3000 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.35\n",
      "INFO:tensorflow:loss = 0.4690067, step = 3100 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.102\n",
      "INFO:tensorflow:loss = 0.47866562, step = 3200 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.998\n",
      "INFO:tensorflow:loss = 0.46315563, step = 3300 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.793\n",
      "INFO:tensorflow:loss = 0.46784967, step = 3400 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.193\n",
      "INFO:tensorflow:loss = 0.45073876, step = 3500 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.937\n",
      "INFO:tensorflow:loss = 0.4503001, step = 3600 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.325\n",
      "INFO:tensorflow:loss = 0.4479322, step = 3700 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.171\n",
      "INFO:tensorflow:loss = 0.43277782, step = 3800 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.278\n",
      "INFO:tensorflow:loss = 0.4266259, step = 3900 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.092\n",
      "INFO:tensorflow:loss = 0.42363095, step = 4000 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.034\n",
      "INFO:tensorflow:loss = 0.41687655, step = 4100 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.923\n",
      "INFO:tensorflow:loss = 0.41474107, step = 4200 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.699\n",
      "INFO:tensorflow:loss = 0.40823123, step = 4300 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.057\n",
      "INFO:tensorflow:loss = 0.41314602, step = 4400 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.784\n",
      "INFO:tensorflow:loss = 0.41134495, step = 4500 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.206\n",
      "INFO:tensorflow:loss = 0.41170394, step = 4600 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.303\n",
      "INFO:tensorflow:loss = 0.40255612, step = 4700 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.7\n",
      "INFO:tensorflow:loss = 0.3934909, step = 4800 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.105\n",
      "INFO:tensorflow:loss = 0.39553696, step = 4900 (0.379 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpzlkzqo2h\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.38455927.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x24280ac0278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 通过调用 Estimator 的 Train 方法来训练模型，如下所示：\n",
    "# 训练模型。\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意将 input_fn 调用封装在 lambda 中以获取参数，同时提供不带参数的输入函数，如 Estimator 所预期的那样。step 参数告知该方法在训练多少步后停止训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.评估经过训练的模型\n",
    "现在模型已经经过训练，您可以获取一些关于模型性能的统计信息。代码块将在测试数据上对经过训练的模型的准确率（accuracy）进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与对 train 方法的调用不同，我们没有传递 steps 参数来进行评估。用于评估的 input_fn 只生成一个 epoch 的数据。\n",
    "\n",
    "eval_result 字典亦包含 average_loss（每个样本的平均误差），loss（每个 mini-batch 的平均误差）与 Estimator 的 global_step（经历的训练迭代次数）值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.利用经过训练的模型进行预测（推理）\n",
    "我们已经有一个经过训练的模型，可以生成准确的评估结果。我们现在可以使用经过训练的模型，根据一些无标签测量结果预测鸢尾花的品种。与训练和评估一样，我们使用单个函数调用进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由模型生成预测\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # 将输入转换为无标签数据集。\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict 方法返回一个 Python 可迭代对象，为每个样本生成一个预测结果字典。以下代码输出了一些预测及其概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
