{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.GPU的使用\n",
    "TensorFlow支持在各种类型的设备上运行计算，包括CPU和GPU。它们用字符串标识符表示，例如：\n",
    "\n",
    "- **\"/device:CPU:0\"**：计算机的CPU。\n",
    "- **\"/GPU:0\"**：TensorFlow可以看到的机器上第一个GPU的简写形式\n",
    "- /job:localhost/replica:0/task:0/device:GPU:1\"：机器的第二个GPU的全限定名称，该名称对TensorFlow可见。\n",
    "\n",
    "如果TensorFlow操作同时具有CPU和GPU实施，则默认情况下，将操作分配给设备时，GPU设备将获得优先级。例如，同时tf.matmul具有CPU和GPU内核。在用设备的系统CPU:0和GPU:0，该GPU:0设备将被选择运行tf.matmul，除非你明确的请求的另一个设备上运行它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.多GPU的单个GPU使用\n",
    "如果系统中有多个GPU，则默认情况下将选择ID最低的GPU。如果要在其他GPU上运行，则需要明确指定首选项："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:2'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.多GPU使用\n",
    "一旦我们有多个逻辑GPU可供运行时使用，就可以在tf.distribute.Strategy手动放置或手动放置时使用多个GPU 。用 tf.distribute.Strategy\n",
    "使用多个GPU的最佳实践是使用tf.distribute.Strategy。这是一个简单的示例：\n",
    "\n",
    "# 具体实现将在下一版本中更新"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
